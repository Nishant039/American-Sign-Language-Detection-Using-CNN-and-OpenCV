{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras import optimizers\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1264: calling reduce_prod_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(128, 128,..., activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3019: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2885: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "\n",
    "#step 1 convolution layer\n",
    "classifier.add(Conv2D(64,3,3,input_shape=(128,128,3),activation='relu'))\n",
    "\n",
    "#step 2 maxpooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#another convolution -maxpooling layer\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(units = 26, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = optimizers.SGD(lr = 0.01), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.load_weights('classifier_weights2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor():\n",
    "       import numpy as np\n",
    "       from keras.preprocessing import image\n",
    "       test_image = image.load_img('1.png', target_size=(128, 128))\n",
    "       test_image = image.img_to_array(test_image)\n",
    "       test_image = np.expand_dims(test_image, axis = 0)\n",
    "       result = classifier.predict(test_image)\n",
    "       \n",
    "       if result[0][0] == 1:\n",
    "              return 'A'\n",
    "       elif result[0][1] == 1:\n",
    "              return 'B'\n",
    "       elif result[0][2] == 1:\n",
    "              return 'C'\n",
    "       elif result[0][3] == 1:\n",
    "              return 'D'\n",
    "       elif result[0][4] == 1:\n",
    "              return 'E'\n",
    "       elif result[0][5] == 1:\n",
    "              return 'F'\n",
    "       elif result[0][6] == 1:\n",
    "              return 'G'\n",
    "       elif result[0][7] == 1:\n",
    "              return 'H'\n",
    "       elif result[0][8] == 1:\n",
    "              return 'I'\n",
    "       elif result[0][9] == 1:\n",
    "              return 'J'\n",
    "       elif result[0][10] == 1:\n",
    "              return 'K'\n",
    "       elif result[0][11] == 1:\n",
    "              return 'L'\n",
    "       elif result[0][12] == 1:\n",
    "              return 'M'\n",
    "       elif result[0][13] == 1:\n",
    "              return 'N'\n",
    "       elif result[0][14] == 1:\n",
    "              return 'O'\n",
    "       elif result[0][15] == 1:\n",
    "              return 'P'\n",
    "       elif result[0][16] == 1:\n",
    "              return 'Q'\n",
    "       elif result[0][17] == 1:\n",
    "              return 'R'\n",
    "       elif result[0][18] == 1:\n",
    "              return 'S'\n",
    "       elif result[0][19] == 1:\n",
    "              return 'T'\n",
    "       elif result[0][20] == 1:\n",
    "              return 'U'\n",
    "       elif result[0][21] == 1:\n",
    "              return 'V'\n",
    "       elif result[0][22] == 1:\n",
    "              return 'W'\n",
    "       elif result[0][23] == 1:\n",
    "              return 'X'\n",
    "       elif result[0][24] == 1:\n",
    "              return 'Y'\n",
    "       elif result[0][25] == 1:\n",
    "              return 'Z'\n",
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoneABCRRRRDFPGX"
     ]
    }
   ],
   "source": [
    "kerneler = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "img_text=''\n",
    "count=0\n",
    "text=[]\n",
    "flag=0\n",
    "img_text_final=''\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    frame=cv2.flip(frame,1)\n",
    "    img = cv2.rectangle(frame, (425, 100), (625, 300), (0, 255, 0), thickness=2, lineType=8, shift=0)\n",
    "    cropped = img[102:298, 427:623]\n",
    "    hsv_converted = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
    "#     hsv_mask=cv2.inRange(hsv_converted,np.array([0, 48, 80]),np.array([20, 255, 255]))\n",
    "    hsv_mask=cv2.inRange(hsv_converted,np.array([0, 20, 70]),np.array([20, 255, 255]))\n",
    "    blurred=cv2.GaussianBlur(hsv_mask,(5,5),0)\n",
    "    _,blurred=cv2.threshold(blurred,20,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "#     cv2.putText(frame, img_text, (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 0))\n",
    "#     dilated=cv2.resize(dilated,(128,128))\n",
    "    \n",
    "    ###\n",
    "    hsv_masknew=cv2.resize(hsv_mask,(128,128))\n",
    "    blurred_new=cv2.resize(blurred,(128,128))\n",
    "    ###\n",
    "    img_name = \"1.png\"\n",
    "    cv2.imwrite(img_name, blurred_new)\n",
    "#     print(\"{} written!\".format(img_name))\n",
    "    img_text = predictor()\n",
    "    text.append(img_text)\n",
    "    text\n",
    "    count=count+1\n",
    "    if(count==50):\n",
    "        flag=1\n",
    "        img_text_final=most_frequent(text)\n",
    "        count=0\n",
    "        text=[]\n",
    "    cv2.putText(frame, img_text_final, (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (0, 255, 0))     \n",
    "    cv2.imshow(\"image\",img)\n",
    "    if(flag==1):\n",
    "        print(img_text_final,end='')\n",
    "        flag=0\n",
    "    \n",
    "#     cv2.imshow(\"cropped\",cropped)\n",
    "#     cv2.imshow(\"hsv_converted\",hsv_converted)\n",
    "#     cv2.imshow(\"hsv mask\",hsv_mask)\n",
    "    cv2.imshow(\"Blurred hsv_mask\",blurred)\n",
    "#     cv2.imshow(\"Dilated hsv_mask\",dilated)\n",
    "    if(cv2.waitKey(5)==27):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### END oF File ## Below Code is not for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-91f1c08a341a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m425\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m625\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineType\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m102\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m298\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m427\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m623\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mhsv_converted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mhsv_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhsv_converted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "kernal = np.ones((3,3),np.uint8)\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11, 11))\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret,frame=cap.read()\n",
    "    frame=cv2.flip(frame,1)\n",
    "    img = cv2.rectangle(frame, (425, 100), (625, 300), (0, 255, 0), thickness=2, lineType=8, shift=0)\n",
    "    cropped = img[102:298, 427:623]\n",
    "    hsv_converted = cv2.cvtColor(cropped, cv2.COLOR_BGR2HSV)\n",
    "    hsv_mask=cv2.inRange(hsv_converted,np.array([0, 20, 70]),np.array([20, 255, 255]))\n",
    "    blurred=cv2.GaussianBlur(hsv_mask,(5,5),0)\n",
    "    _,blurred=cv2.threshold(blurred,20,255,cv2.THRESH_BINARY)\n",
    "#     dilated=cv2.dilate(blurred,kernal,iterations=2)\n",
    "\n",
    "\n",
    "#     eroded = cv2.erode(blurred, kernel, iterations = 1)\n",
    "    dilated = cv2.dilate(blurred, kernel, iterations = 1)\n",
    "    \n",
    "    dilated=cv2.resize(dilated,(128,128))\n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"image\",img)\n",
    "    cv2.imshow(\"cropped\",cropped)\n",
    "#     cv2.imshow(\"hsv_converted\",hsv_converted)\n",
    "    cv2.imshow(\"hsv mask\",hsv_mask)\n",
    "#     cv2.imshow(\"Blurred hsv_mask\",blurred)\n",
    "    cv2.imshow(\"Dilated hsv_mask\",dilated)\n",
    "    if(cv2.waitKey(1)==27):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dilated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img('1.png', target_size=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAByUlEQVR4nO2ZQa6CMBBAR0KMbFyZyNaoCUchnsAjcBKDJ8AbuPMaxpUH8ALsWdDERV2YTwz+VGZoy5DMWylQOo+h7QAAgiAIgiAIgsCR4/Go/9hsNkOH8z+BYd98Pm9+Px6Puq7dx4PGJNBiNpu5i4PMxLxba91uMPnRxDOIDPDEJLBarb43vkdCFEXN+G52XS4X/cFutwOAIAg+N263W9sKRrQD0jQFgDRN338Xi8XIBL7Z7/dOoi+Kwo+A/poqusNlEJMdTHNinwtDgDZBc8kAABRFQWjFKANASgKjDACpWuElQMAkcDqdvMVBhlcGCBU7LwHAO7ATwCICQyMCQ8OrlACA5/M5nU67H89OAJAVkekWut/vvYNxjkngdrt5i4MM+r2QB6zdQthzDcLvaZS5Q6d1gLND14VsvV47jYMM7tL6GdM2B3GLKIqQwaBRSqGOxwkopTw4oEAXc0qpsixdhOKVJEm4vSRFc71erUfv+ytW845/rAIAcD6fxy0AAFmW2RIg9G6nRqD13aKqqs8v0x2x80xspVg6HA6Urvt3/KZ/Ekb/gSOOY0IrRgI0rAnkeW7rVCgkA/YYuEYMw7DnKrZcLgn9vgBpUXd2oUyzwwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x2A7938477F0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([[[0,1,2],[3,4,5]],[[2,3,4],[5,6,7]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count) \n",
    "  \n",
    "List = [\"A\",\"B\",\"A\",\"B\",\"B\"] \n",
    "print(most_frequent(List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
